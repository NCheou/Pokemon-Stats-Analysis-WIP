{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c12ca336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports requests.get, beautiful soup, manipulating csvs, os for current path, and re for regular expressions\n",
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b4fe360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishes a base URL that we then append new pokemon links to. \n",
    "rootURL = \"https://bulbapedia.bulbagarden.net\"\n",
    "#The indexURL starts at Miraidon that's the most recent pokemon, so after this it loops back to Bulbasaur. \n",
    "indexURL = rootURL + '/wiki/Miraidon_(Pokémon)'\n",
    "#Creates an empty list to append pokemon stats to\n",
    "allPokemonData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bc1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80d8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the location of the CSV we are writing to. Currently, it requires an existing CSV named Pokemonstats \n",
    "#As it was easier to do.\n",
    "csv_file = currentPath + '\\Pokemonstats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4bb103c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the names of the columsn in the CSV\n",
    "csv_columns = ['National Dex Number', 'Name', 'Type 1', 'Type 2', 'HP', 'Attack', 'Defense', 'Sp. Attack', 'Sp. Defense', 'Speed', 'Stat Total', 'Weight (kg)', 'Height (m)', 'Generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b93e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getPokemonURLs():\n",
    "    #soup = bs4.BeautifulSoup(requests.get(indexURL).content, 'html.parser')\n",
    "    #next_pokemon_url_table = soup.find_all('td', style='text-align: left')\n",
    "    #next_pokemon_url = \"https:/bulbapedia.bulbagarden.net\" + '/' + next_pokemon_url_table[0].find('a', href=True)['href']\n",
    "    #return next_pokemon_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2ffd5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates a function to get the URL for the next pokemon. It finds 'Name_(Pokemon)' and appends it to the\n",
    "#rootURL to create a the URL for the next pokemon. It does this 1006 times as that's how many pokemon there are. \n",
    "#It would need to be updated when new pokemon are released. \n",
    "#We use yield here because if you use return, it breaks a while loop.\n",
    "def getPokemonURLs():\n",
    "    soup = bs4.BeautifulSoup(requests.get(indexURL).content, 'html.parser')\n",
    "    next_pokemon_url_table = soup.find_all('td', style='text-align: left')[0].find('a', href=True)['href']\n",
    "    #new_URL = next_pokemon_url_table[0].find('a', href=True)['href']\n",
    "    next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + next_pokemon_url_table\n",
    "    count = 0    \n",
    "    yield(next_pokemon_url)\n",
    "    while count <1007:\n",
    "        next_pokemon_url_table = bs4.BeautifulSoup(requests.get(next_pokemon_url).content, 'html.parser').find_all('td', style='text-align: left')[0].find('a', href=True)['href']\n",
    "        #new_URL = next_pokemon_url_table[0].find('a', href=True)['href'][0].find('a', href=True)['href']\n",
    "        next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + next_pokemon_url_table\n",
    "        yield(next_pokemon_url)\n",
    "        count += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb76c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes a pokemon URL and scrapes all the data we want. We start with a list consisting of 14 zeroes, then we \n",
    "#replace each zero with the info we want.\n",
    "def getPokemonData(inputURL):\n",
    "    pokemonData = [0]*14 \n",
    "    #htmlData    = requests.get( rootURL + inputURL)\n",
    "    #this line seems to do https://bulbapedia.bulbagarden.net + https://bulbapedia.bulbagarden.net/wiki/Ivysaur_(Pokémon). \n",
    "    #we want only the full link\n",
    "    htmlData  = requests.get(inputURL)\n",
    "    soup      = bs4.BeautifulSoup(htmlData.text, \"html.parser\" )\n",
    "    #These next two lines are for finding the generation of the pokemon\n",
    "    name_soup = soup.select('ul li span a[class*=\"external text\"]')\n",
    "    name_soup = bs4.BeautifulSoup(str(name_soup)).get_text()\n",
    "    \n",
    "    #This looks for the national dex number. Unfortunately at this time, the national dex numbers for \n",
    "    #generation 9 have not been updated yet, so they were manually put in.\n",
    "    pokemonData[0] = soup.th.big.a.span.text\n",
    "    \n",
    "    #This returns the name of the pokemon, and gets rid of all special characters.\n",
    "    #Nidoran gave me issues because its name has a gender symbol in it, and I couldn't\n",
    "    #write that symbol to a csv\n",
    "    pokemonData[1] = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", (soup.select('h1#firstHeading')[0].get_text())[:-10])\n",
    "    \n",
    "    #This looks for the a class that contains the type and gets the first element\n",
    "    pokemonData[2] = soup.select('td a[href*=\"(type)\"] span b')[0].get_text()\n",
    "    \n",
    "    #Some pokemon have two typings, so what this does is it gets [1] and if the\n",
    "    #pokemon doesn't have a second type, it will return 'Unknown'. If it returns\n",
    "    #that, it will copy the mono type over to the Type 2 column. \n",
    "    if soup.select('a[href*=\"(type)\"] span b')[1].get_text() != 'Unknown':\n",
    "        pokemonData[3] = soup.select('td[width = \"45px\"] a[href*=\"(type)\"] span b')[1].get_text()\n",
    "    if soup.select('a[href*=\"(type)\"] span b')[1].get_text() == 'Unknown':\n",
    "        pokemonData[3] = soup.select('td a[href*=\"(type)\"] span b')[0].get_text()\n",
    "    #This finds the div class with style 'float:right' which only appears on the base stats table\n",
    "    #The first element corresponds to HP, Attack, etc and then transforms it into an integer\n",
    "    pokemonData[4] = (int)(soup.find_all('div', attrs={'style':'float:right'})[0].get_text())\n",
    "    pokemonData[5] = (int)(soup.find_all('div', attrs={'style':'float:right'})[1].get_text())\n",
    "    pokemonData[6] = (int)(soup.find_all('div', attrs={'style':'float:right'})[2].get_text())\n",
    "    pokemonData[7] = (int)(soup.find_all('div', attrs={'style':'float:right'})[3].get_text())\n",
    "    pokemonData[8] = (int)(soup.find_all('div', attrs={'style':'float:right'})[4].get_text())\n",
    "    pokemonData[9] = (int)(soup.find_all('div', attrs={'style':'float:right'})[5].get_text())\n",
    "    pokemonData[10] = (int)(soup.find_all('div', attrs={'style':'float:right'})[6].get_text())\n",
    "    \n",
    "    #This looks for the weight of the pokemon in kilograms. It does this by finding the a href title:Weight\n",
    "    #Then going up two levels with .parent.parent. then it finds the first 'td' under it, which contains \n",
    "    #two elements. [0] is in pounds, [1] is in kg. I chose to .split() to get only the float\n",
    "    #because otherwise it would report 1 kg instead of just 1.\n",
    "    pokemonData[11] = (float)(soup.find('a', {'title': 'Weight'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "    pokemonData[12] = (float)(soup.find('a', {'title': 'List of Pokémon by height'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "    #This line finds the generation by going to the list of generations the pokemon appears in and finding the first one\n",
    "    #For some reason, the wiki uses a different format for generations 8 and 9, so this doesn't get the generation\n",
    "    #for those pokemon. Those were input manually, but it's fairly easy. \n",
    "    pokemonData[13] = name_soup[:-1][1:].split(',')[0]\n",
    "    \n",
    "    allPokemonData.append(pokemonData)\n",
    "    #print(allPokemonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c465d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getPokemonData(inputURL):\n",
    "#     pokemonData = [0]*11 #start with 11 0s. Better than using append method each time to add new value\n",
    "#     #htmlData    = requests.get( rootURL + inputURL)\n",
    "#     #this line seems to do https://bulbapedia.bulbagarden.net + https://bulbapedia.bulbagarden.net/wiki/Ivysaur_(Pokémon). \n",
    "#     #we want only the full link\n",
    "#     htmlData = requests.get(inputURL)\n",
    "#     soup        = bs4.BeautifulSoup(htmlData.text, \"html.parser\" )\n",
    "                               \n",
    "#     pokemonData[0] = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", (soup.select('h1#firstHeading')[0].get_text())[:-10])\n",
    "    \n",
    "#     pokemonData[1] = soup.select('td a[href*=\"(type)\"] span b')[0].get_text()\n",
    "    \n",
    "#     if soup.select('a[href*=\"(type)\"] span b')[1].get_text() != 'Unknown':\n",
    "#         pokemonData[1] += '/' + soup.select('td[width = \"45px\"] a[href*=\"(type)\"] span b')[1].get_text()\n",
    "    \n",
    "#     pokemonData[2] = (int)(soup.find_all('div', attrs={'style':'float:right'})[0].get_text())\n",
    "#     pokemonData[3] = (int)(soup.find_all('div', attrs={'style':'float:right'})[1].get_text())\n",
    "#     pokemonData[4] = (int)(soup.find_all('div', attrs={'style':'float:right'})[2].get_text())\n",
    "#     pokemonData[5] = (int)(soup.find_all('div', attrs={'style':'float:right'})[3].get_text())\n",
    "#     pokemonData[6] = (int)(soup.find_all('div', attrs={'style':'float:right'})[4].get_text())\n",
    "#     pokemonData[7] = (int)(soup.find_all('div', attrs={'style':'float:right'})[5].get_text())\n",
    "#     pokemonData[8] = (int)(soup.find_all('div', attrs={'style':'float:right'})[6].get_text())\n",
    "    \n",
    "#     pokemonData[9] = (float)(soup.find('a', {'title': 'Weight'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "#     pokemonData[10] = (float)(soup.find('a', {'title': 'List of Pokémon by height'}).parent.parent.find_all('td')[1].get_text().split()[0])\n",
    "    \n",
    "#     allPokemonData.append(pokemonData)\n",
    "#     #print(allPokemonData)\n",
    "#this is my first get Pokemon Data. The difference is that I added a 'Type 2' column for dual typing, and wrote a line to \n",
    "#check if there's no dual typing, then just add the mono type for 'Type 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0e32280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the list of pokemon URLs generated and scrapes the stats from the first URL\n",
    "#then iterates through the rest of them until it's finished. \n",
    "def allPokemonStats():\n",
    "    pokemonURLs = getPokemonURLs()\n",
    "    #counter = 0\n",
    "    #while counter < 1007:    \n",
    "    for pokemonURL in pokemonURLs:\n",
    "        getPokemonData(pokemonURL)\n",
    "        #counter += 1\n",
    "    #print(allPokemonData)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1440673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This writes to an existing CSV\n",
    "def WriteListToCSV(csv_file, csv_columns, data_list):\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(csv_columns) #include if you want to have the csv column names too\n",
    "        for data in data_list:\n",
    "            writer.writerow(data)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0c9b4f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#print(getPokemonData('https://bulbapedia.bulbagarden.net/wiki/Blastoise_(Pokémon)'))\n",
    "#I used this print statement to test single pokemon URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc914634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(allPokemonData)\n",
    "#This prints out what's in the allPokemonData list after I test URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPokemonStats()\n",
    "#I originally got a list index out of range error on this because I tried Mr. Mime came up. My previous\n",
    "#getPokemonURLs used .split'_' to separate the pokemon's name from ('Pokemon'), as it would give me unicode for é. I thought\n",
    "#that was throwing up issues, but I realized it wasn't, so I changed deleted it and it was fine. \n",
    "#def getPokemonURLs():\n",
    "#     soup = bs4.BeautifulSoup(requests.get(indexURL).content, 'html.parser')\n",
    "#     count = 0 \n",
    "#     next_pokemon_url_table = soup.find_all('td', style='text-align: left')\n",
    "#     new_URL = next_pokemon_url_table[0].find('a', href=True)['href'].split('_')[0]\n",
    "#     next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + new_URL + '_(Pokémon)'\n",
    "#     yield(next_pokemon_url)\n",
    "#     while count <1007:\n",
    "#         next_pokemon_url_table = bs4.BeautifulSoup(requests.get(next_pokemon_url).content, 'html.parser').find_all('td', style='text-align: left')\n",
    "#         new_URL = next_pokemon_url_table[0].find('a', href=True)['href'].split('_')[0]\n",
    "#         next_pokemon_url = \"https://bulbapedia.bulbagarden.net\" + new_URL + '_(Pokémon)'\n",
    "#         yield(next_pokemon_url)\n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "04d10575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executes CSV function\n",
    "WriteListToCSV( csv_file, csv_columns, allPokemonData )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "095efd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bulbapedia.bulbagarden.net/wiki/Bulbasaur_(Pokémon)\n",
      "https://bulbapedia.bulbagarden.net/wiki/Ivysaur_(Pokémon)\n",
      "https://bulbapedia.bulbagarden.net/wiki/Venusaur_(Pokémon)\n",
      "https://bulbapedia.bulbagarden.net/wiki/Charmander_(Pokémon)\n"
     ]
    }
   ],
   "source": [
    "#I used this to test the function works correctly. \n",
    "for value in getPokemonURLs():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea8745e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Psychic'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bs4.BeautifulSoup(requests.get('https://bulbapedia.bulbagarden.net/wiki/Mr._Mime_(Pok%C3%A9mon)').content, \"html.parser\" ).select('td a[href*=\"(type)\"] span b')[3].get_text()\n",
    "#I used this to test the issues with Mr. Mime. At first I thought it was because of its Galarian form and extra typings were \n",
    "#throwing if off, so I was making sure the typing worked. It turns out it was just the URL itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0eb8ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Executes the pokemon stats function\n",
    "allPokemonStats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63e6e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bs4.BeautifulSoup(requests.get('https://bulbapedia.bulbagarden.net/wiki/Blastoise_(Pokémon)').text, \"html.parser\" ).select('td a[href*=\"(type)\"] span b')[1].get_text()\n",
    "#I used this to test what happens when you request the second type of a pokemon with mono typing. It returns 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cd593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
